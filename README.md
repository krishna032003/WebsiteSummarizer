# ğŸŒ Website Summarizer

> *Transform any webpage into intelligent, AI-powered summaries with local LLM magic* âœ¨

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-green.svg)](https://ollama.ai)
[![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-Web%20Scraping-orange.svg)](https://www.crummy.com/software/BeautifulSoup/)

---

## âœ¨ What It Does

This sleek Python tool combines **web scraping** with **local AI** to deliver crystal-clear website summaries. No API keys, no cloud dependencyâ€”just pure local intelligence powered by Ollama.

```python
# One line to rule them all
display_summary("https://your-favorite-site.com")
```

---

## ğŸš€ Features

| Feature | Description |
|---------|-------------|
| ğŸ•·ï¸ **Smart Scraping** | Intelligently extracts content while filtering noise |
| ğŸ¤– **Local AI Power** | Llama 3.2 running on your machineâ€”complete privacy |
| ğŸ“ **Markdown Magic** | Beautiful, formatted summaries ready to use |
| ğŸ¯ **Content Focus** | Ignores navigation clutter, focuses on the good stuff |
| ğŸ“Š **Jupyter Ready** | Built-in display functions for notebooks |

---

## ğŸ› ï¸ Quick Setup

### Prerequisites
- ğŸ¦™ **Ollama** running on `localhost:11434`
- ğŸ§  **Llama 3.2** model installed
- ğŸ **Python 3.7+**

### Installation
```bash
# Install the magic ingredients
pip install requests beautifulsoup4 python-dotenv openai ipython

# Start your local AI engine
ollama serve
ollama pull llama3.2
```

---

## ğŸ® Usage

### ğŸ¯ Quick Start
```python
from website_summarizer import summarize, display_summary

# Get instant insights
summary = summarize("https://techcrunch.com")
print(summary)

# Jupyter notebook magic âœ¨
display_summary("https://hackernews.com")
```

### ğŸ”§ Power User Mode
```python
# Deep dive into any website
website = Website("https://example.com")
print(f"ğŸ“„ Title: {website.title}")
print(f"ğŸ“ Preview: {website.text[:200]}...")

# Custom AI conversations
messages = messages_for(website)
```

---

## ğŸ—ï¸ Architecture

<div align="center">

```mermaid
graph LR
    A[ğŸŒ URL] --> B[ğŸ•·ï¸ Website Class]
    B --> C[ğŸ§¹ Content Cleanup]
    C --> D[ğŸ¤– AI Processing]
    D --> E[ğŸ“ Markdown Summary]
```

</div>

### ğŸ­ Core Components

#### `Website` Class
The web scraping superhero that:
- ğŸ¯ Fetches any URL with stealth headers
- ğŸ§¹ Strips away navigation noise
- ğŸ“„ Extracts pure, valuable content

#### `summarize()` Function
Your AI summarization wizard:
- ğŸ¤– Connects to local Ollama instance
- ğŸ’¬ Crafts perfect prompts
- âœ¨ Returns markdown-formatted insights

---

## âš™ï¸ Configuration

### ğŸ•µï¸ Stealth Mode Headers
```python
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}
```

### ğŸ§  AI Personality
```python
system_prompt = """
You are an assistant that analyzes websites and provides short summaries,
ignoring navigation clutter. Respond in beautiful markdown.
"""
```

---

## ğŸ¨ Customization Playground

### ğŸ”„ Switch AI Models
```python
response = openai.chat.completions.create(
    model="mistral",  # Try different models!
    messages=messages_for(website)
)
```

### ğŸŒ Multilingual Magic
```python
system_prompt = "Analyze websites and respond in elegant Spanish markdown."
```

### ğŸ›ï¸ Content Filtering
```python
# Remove even more noise
for noise in soup.body(["script", "style", "img", "nav", "footer", "aside"]):
    noise.decompose()
```

---

## ğŸ¯ Real-World Examples

```python
# ğŸ“° News Analysis
display_summary("https://news.ycombinator.com")

# ğŸ“š Documentation Digest  
display_summary("https://docs.python.org")

# ğŸ¢ Company Research
summary = summarize("https://openai.com")
```

---

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| ğŸš« Connection Error | `ollama serve` then retry |
| ğŸ¤– Model Missing | `ollama pull llama3.2` |
| ğŸ“¦ Import Fails | `pip install -r requirements.txt` |
| ğŸ›¡ï¸ Site Blocks You | Check headers, try different sites |

### ğŸ©º Health Check
```bash
# Verify Ollama is alive
curl http://localhost:11434/api/tags

# Test model availability
ollama list
```

---

## ğŸŒŸ Pro Tips

> ğŸ’¡ **Performance Tip**: Use `llama3.2:1b` for faster summaries on slower machines

> ğŸ¯ **Quality Tip**: Add specific instructions to your system prompt for domain-specific content

> ğŸ”’ **Privacy Win**: Everything runs locallyâ€”your data never leaves your machine

---

## ğŸ¤ Contributing

Found a bug? Have an idea? 

1. ğŸ´ Fork it
2. ğŸŒŸ Star it  
3. ğŸ› Fix it
4. ğŸ“¤ PR it

---

## ğŸ“œ License

**MIT Licensed** - Use it, modify it, love it! ğŸ’–

---

<div align="center">

**Built with â¤ï¸ by developers, for developers**

*Transform the web, one summary at a time* ğŸŒâ¡ï¸ğŸ“

</div>
